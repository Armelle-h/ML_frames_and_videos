{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ6OTISqU0mrJx8lbAjClN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Armelle-h/ML_frames_and_videos/blob/main/test_set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot4eXPlKiSCM",
        "outputId": "b76c5d76-04d1-483d-ba12-980e605b969c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/ML_project_frames_and_videos')"
      ],
      "metadata": {
        "id": "nLfazAGUiVFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from functools import partial\n",
        "from torch.utils.data import DataLoader\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "! pip install ftfy #needed for CLIP to run\n",
        "! pip install torchmetrics\n",
        "import torchmetrics\n",
        "\n",
        "import os\n",
        "import math\n",
        "\n",
        "from Pair_Frames import Pair_Frames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtdAvQJviVHx",
        "outputId": "5db9977c-5ff0-411d-d565-d2eaa51583a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy) (0.2.5)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_Similarity_Pair_Frames(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #Remplir les fonctions d'activations ici nn.Relu, nn.Linear\n",
        "    self.input_layer = torch.nn.Linear(1024, 250) #1024, the size of 2 feature vectors concatenated, 250 the number of neurons in our hidden layers\n",
        "    self.input_phi = torch.nn.ReLU()\n",
        "    self.layer1 = torch.nn.Linear(250, 250) #constructed as \"(number of in-edges, number of out-edges)\"\n",
        "    self.phi1 = torch.nn.ReLU()\n",
        "    self.layer2 = torch.nn.Linear(250, 250)\n",
        "    self.phi2 = torch.nn.ReLU()\n",
        "    self.output_layer = torch.nn.Linear(250, 2) #our model outputs pair of values coresponding to \"(P['not the same video], P['same video'])\"\n",
        "\n",
        "  def forward(self,PF):\n",
        "    \"\"\"PF a pair of frames\"\"\"\n",
        "    #put the forward pass of the neural network using the activations functions\n",
        "    PF = self.input_layer(PF)\n",
        "    PF = self.input_phi(PF) #activation function on first layer\n",
        "    PF = self.layer1(PF)\n",
        "    PF = self.phi1(PF)\n",
        "    PF = self.layer2(PF)\n",
        "    PF = self.phi2(PF)\n",
        "    PF = self.output_layer(PF)\n",
        "    return PF"
      ],
      "metadata": {
        "id": "1Fi19od1iVKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to load a trained model:\n",
        "\n",
        "#by default loads the last model\n",
        "name=os.listdir('/content/drive/MyDrive/ML_project_frames_and_videos/trained_models')[-1]\n",
        "lr = 5e-3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Model_Similarity_Pair_Frames()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "checkpoint = torch.load(os.path.join('/content/drive/MyDrive/ML_project_frames_and_videos/trained_models', name), map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "num_epochs = checkpoint['epoch']\n",
        "criterion = checkpoint['loss']\n",
        "\n",
        "print(f\"Previously trained for {num_epochs} number of epochs and with the loss function {criterion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0ts4SgviVM9",
        "outputId": "6b296325-e19f-453c-d274-96b1dd95fcac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previously trained for 2 number of epochs and with the loss function <function cross_entropy at 0x7f570ac67d30>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_dir='/content/drive/MyDrive/ML_project_frames_and_videos/DATA/videos'\n",
        "length=10000 #length can be tuned\n",
        "length_test=math.floor(0.15*length)\n",
        "test_set = Pair_Frames(video_dir, train=2, length=length_test, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6duDIkScir8x",
        "outputId": "6c009ddb-06ab-42fe-bcf7-4d370a300c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 338M/338M [00:02<00:00, 125MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size=128\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        test_set,\n",
        "        batch_size=batch_size,\n",
        "    )"
      ],
      "metadata": {
        "id": "sT3Ji56GihoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad() #'reset' gradients\n",
        "def validate(model, device, test_loader, criterion):\n",
        "    model.eval()  # Important set model to eval mode (affects dropout, batch norm etc)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for batch_idx, (feature1, feature2, label) in enumerate(test_loader):\n",
        "      feature1 = feature1.to(device).float() #change to device selected\n",
        "      feature2 = feature2.to(device).float()\n",
        "      target =label.to(device)\n",
        "      if feature1.shape[0]==1: #there was an issue if the tensor had shape (1,n)\n",
        "        f1=torch.flatten(feature1, 0)\n",
        "        f2=torch.flatten(feature2, 0)\n",
        "        data = torch.cat([f1, f2])\n",
        "        output = model(data)\n",
        "        output=output.reshape([1, output.shape[0]])\n",
        "      else:\n",
        "        data=torch.cat([feature1, feature2], dim=1)\n",
        "        output = model(data)\n",
        "      test_loss += criterion(output, target).item() * len(data) #weighted sum\n",
        "\n",
        "      pred = output.argmax(dim=1, keepdim=True) #idea is that our model output a pair of proba. With this command, we keep only the index\n",
        "        #indicating where the highest value is and we do this column-wise\n",
        "\n",
        "      correct +=pred.eq(target.view_as(pred)).sum().item() #this counts the number of good answers we had when comparing to our target and adds\n",
        "        #them to the number of already well predicted pair of frames.\n",
        "        #the target has value 0 if \"data[0]\" belongs to two different videos and value 1 if it belongs to the same\n",
        "\n",
        "    test_loss /= len(test_loader.dataset) #we renormalize as we did a weighted sum\n",
        "\n",
        "    print(\n",
        "        \"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\".format(\n",
        "            test_loss,\n",
        "            correct,\n",
        "            len(test_loader.dataset),\n",
        "            100.0 * correct / len(test_loader.dataset),\n",
        "        )\n",
        "    )\n",
        "    return test_loss, correct / len(test_loader.dataset)"
      ],
      "metadata": {
        "id": "4fn9yc5Hi-Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(model, device, test_loader, criterion)"
      ],
      "metadata": {
        "id": "nV2FbBI8jyaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0962cc-e6d0-4527-d5c5-f5143c307fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.3186, Accuracy: 1318/1500 (88%)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3185728220144908, 0.8786666666666667)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hNfsuXUh3iby"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}